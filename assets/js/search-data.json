{
  
    
        "post0": {
            "title": "Getting started with Acoular",
            "content": "import acoular . We want to analyze time histories from 64 microphones stored in the file &quot;three_sources.h5&quot;. . This file is in HDF5 format, which is an open all purpose numerical data container file format. Have a look at the file! You will need an HDF5 file viewer (e.g. https://www.hdfgroup.org/downloads/hdfview/) . ts = acoular.TimeSamples( name=&quot;three_sources.h5&quot; ) . ts . &lt;acoular.sources.TimeSamples at 0x7f7199f8fc50&gt; . How many channels and samples do we have? What is the sampling frequency? This information is available from the ts object. . print(ts.numchannels,ts.numsamples,ts.sample_freq) . 64 51200 51200.0 . To work in the frequency domian, we need the cross spectral matrix. The cross spectral matrix is computed using Welch&#39;s method. Block size and window have to be defined. . ps = acoular.PowerSpectra( time_data=ts, block_size=128, window=&quot;Hanning&quot; ) ps.fftfreq() . array([ 0., 400., 800., 1200., 1600., 2000., 2400., 2800., 3200., 3600., 4000., 4400., 4800., 5200., 5600., 6000., 6400., 6800., 7200., 7600., 8000., 8400., 8800., 9200., 9600., 10000., 10400., 10800., 11200., 11600., 12000., 12400., 12800., 13200., 13600., 14000., 14400., 14800., 15200., 15600., 16000., 16400., 16800., 17200., 17600., 18000., 18400., 18800., 19200., 19600., 20000., 20400., 20800., 21200., 21600., 22000., 22400., 22800., 23200., 23600., 24000., 24400., 24800., 25200., 25600.]) . ps.csm.shape . [(&#39;three_sources_cache.h5&#39;, 1)] . (65, 64, 64) . We need the microphone positions and read them from a file. Have a look at the XML file using a text editor! . The mg object now contains all information about the microphone positions. . mg = acoular.MicGeom( from_file=&quot;array_64.xml&quot;) mg.mpos . array([[ 0.152 , 0.134 , 0.1043, 0.0596, 0.0798, 0.0659, 0.0262, 0.0272, 0. , 0.004 , 0.0162, 0.0162, 0.004 , -0.0112, -0.018 , -0.0112, -0.145 , -0.1294, -0.1242, -0.1209, -0.0828, -0.0631, -0.0595, -0.034 , 0.0056, 0.0037, -0.016 , -0.0492, -0.0024, 0.0022, -0.0267, -0.0054, -0.0874, -0.0764, -0.049 , -0.0058, -0.0429, -0.0378, 0.0003, -0.0121, -0.1864, -0.1651, -0.1389, -0.1016, -0.1008, -0.0809, -0.0475, -0.0369, 0.1839, 0.1634, 0.146 , 0.1235, 0.1019, 0.0799, 0.0594, 0.0393, 0.0774, 0.0697, 0.0778, 0.0944, 0.0473, 0.0338, 0.0478, 0.0218], [ 0.1141, 0.1021, 0.1036, 0.1104, 0.0667, 0.0497, 0.0551, 0.0286, 0. , -0.0175, -0.0078, 0.0078, 0.0175, 0.0141, 0. , -0.0141, 0.1228, 0.1079, 0.0786, 0.0335, 0.0629, 0.0531, 0.0133, 0.0202, 0.1899, 0.1685, 0.1461, 0.1155, 0.104 , 0.0825, 0.0548, 0.0391, -0.1687, -0.1502, -0.1386, -0.1254, -0.0947, -0.0733, -0.061 , -0.0376, -0.0368, -0.0339, -0.0481, -0.0736, -0.0255, -0.0162, -0.0382, -0.014 , -0.0477, -0.0411, -0.0169, 0.0223, -0.0208, -0.0205, 0.0138, -0.0034, -0.1735, -0.1534, -0.1247, -0.0827, -0.0926, -0.0753, -0.0378, -0.0329], [ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]]) . Now let us plot the microphone geometry. We use the matplotlib package. . %matplotlib notebook import matplotlib.pylab as plt plt.plot(mg.mpos[0],mg.mpos[1],&#39;o&#39;) plt.axis(&#39;equal&#39;) . (-0.204915, 0.202415, -0.19166999999999998, 0.20807) . To map the sound, we need a mapping grid. Here we construct a simple regular and rectangular grid. Note that we have to decide about the size, spacing and distance from array. . rg = acoular.RectGrid( x_min=-0.2, x_max=0.2, y_min=-0.2,y_max=0.2, z=0.3,increment=0.01 ) rg.pos() . array([[-0.2 , -0.2 , -0.2 , ..., 0.2 , 0.2 , 0.2 ], [-0.2 , -0.19, -0.18, ..., 0.18, 0.19, 0.2 ], [ 0.3 , 0.3 , 0.3 , ..., 0.3 , 0.3 , 0.3 ]]) . One important element in beamforming and similar methods is the steering vector. This vector &#39;connects&#39; grid and microphones and takes into account the environmental conditions. If not set explicitely, a &#39;standard&#39; environment is created which assumes no flow and a speed of sound of 343 m/s. . st = acoular.SteeringVector( grid = rg, mics=mg ) . st.env.c . 343.0 . Now, we set up a standard beamformer. . bb = acoular.BeamformerBase( freq_data=ps, steer=st) . Lazy evaluation. No computation yet! . This means although we set up everything needed to perform beamforming, calculation is postponed until the results are actually needed. . This will happen if we ask for the result. In this example we are interested in the sum for of all FFT frequency lines in the 3rd octave band 8000 Hz. . pm = bb.synthetic(8000,3) Lm = acoular.L_p(pm) . [(&#39;three_sources_cache.h5&#39;, 2)] . The map is now stored in the array pm and the array Lm holds the soundpressure levels computed from this. . print(Lm.shape) print(Lm) . (41, 41) [[-350. -350. -350. ... -350. -350. -350. ] [-350. -350. 61.51850875 ... -350. -350. -350. ] [ 66.42663667 65.93676969 68.35014819 ... -350. -350. -350. ] ... [-350. -350. -350. ... -350. -350. -350. ] [-350. 54.71250077 46.46416286 ... 48.39370444 58.52533737 -350. ] [ 58.13562703 62.27400942 61.09820506 ... -350. 61.88124704 61.96166613]] . The map has the same dimensions (41 x 41) as the grid. Any zero result in the map will be transferred to -350 dB level. . Lets plot the map with 10 dB dynamic range. . plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-10,extent=rg.extend()) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f7198b61fd0&gt; . After we have enjoyed this result which was computed using the diagonal removal technique (the default), we want to see the result with the full CSM including the diagonal. We set the flag of the bb object. . bb.r_diag = False . Obvious nothing happens (right away). Lazy evaluation again. Have a look at the documentation on BeamformerBase. Now ask for the result and plot it. . Lm = acoular.L_p(bb.synthetic(8000,3)) plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-10,extent=rg.extend()) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f7198993c50&gt; . Nice! . Changes in other objects will also affect the beamformer. To try this out, we change the file name in the ts object. Now this object gets new time histories. The ps and bb objects &#39;know&#39; about this automatically. No need to inform these other objects about the change. We can immediately ask for the result and it will be computed. . ts.name=&quot;two_sources.h5&quot; Lm = acoular.L_p(bb.synthetic(8000,3)) plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-15,extent=rg.extend()) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f7198774f10&gt; . There are only two sources. The result is different, obviously! . Now let us try a different type of beamformer. Instead of standard beamforming, we use functional beamforming instead. We set up a new object (bf) and specify the gamma parameter which is specific to that type of beamformer. We also use the same time histories as before. . ts.name=&quot;three_sources.h5&quot; bf = acoular.BeamformerFunctional(freq_data=ps, steer=st, gamma=50) Lm = acoular.L_p(bf.synthetic(8000,3)) plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-15,extent=rg.extend()) plt.colorbar() . [(&#39;two_sources_cache.h5&#39;, 2), (&#39;three_sources_cache.h5&#39;, 1)] [(&#39;two_sources_cache.h5&#39;, 1), (&#39;three_sources_cache.h5&#39;, 2)] . &lt;matplotlib.colorbar.Colorbar at 0x7f7198242fd0&gt; . Note the much smaller lobes of this beamformer. . Instead of just beamforming we can do deconvolution. This is done exactly the same way using a &#39;beamformer&#39; with CleanSC deconvolution method. Despite the python class name we chose it is not just a beamformer. . ts.name=&quot;three_sources.h5&quot; bs = acoular.BeamformerCleansc(freq_data=ps, steer=st) Lm = acoular.L_p(bs.synthetic(8000,3)) plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-15,extent=rg.extend()) plt.colorbar() . [(&#39;two_sources_cache.h5&#39;, 1), (&#39;three_sources_cache.h5&#39;, 3)] . &lt;matplotlib.colorbar.Colorbar at 0x7f719819bad0&gt; . Now there is just one grid &#39;point&#39; per source. . All computed results are cached. This means at the next start of this notebook no recalculation is necessary and all results are immedately available! . bs1 = acoular.BeamformerCleansc(freq_data=ps, steer=st) Lm = acoular.L_p(bs1.synthetic(8000,3)) plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-15,extent=rg.extend()) plt.colorbar() . [(&#39;two_sources_cache.h5&#39;, 1), (&#39;three_sources_cache.h5&#39;, 4)] . &lt;matplotlib.colorbar.Colorbar at 0x7f71980eab10&gt; . Cache is not used when parameters are changing. . print(bs.damp) bs.damp = 0.99 . 0.6 . Now a new computation is necessary. . Lm = acoular.L_p(bs.synthetic(8000,3)) plt.figure() plt.imshow(Lm.T,origin=&quot;lower&quot;, vmin=Lm.max()-15,extent=rg.extend()) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f718af40d50&gt; . Time domain processing . For processing in time domain, one may set up &#39;chains&#39; of processing blocks. This is very flexible and allows for easy implementation of new algorithms or algorithmic steps. . Here we set up the following processing chain: . data intake from file (TimeSamples, same as before) | beamforming | band pass filtering (the time history for each point in the map is filtered) | power estimation (just the square, nothing else) | linear average over consecutive blocks in time | In order to speed things up, we make the grid a bit more coarse. . rg.increment = 0.025 bt = acoular.BeamformerTime(source=ts, steer=st) ft = acoular.FiltOctave(source=bt, band=8000, fraction=&#39;Third octave&#39;) pt = acoular.TimePower(source=ft) avgt = acoular.TimeAverage(source=pt, naverage = 6400) . And again: lazy evaluation, nothing is computed yet. . Only asking for the result will initiate computing. Although this is not used here, the architecture allows for endless data processing from a stream of input data. . res = [r for r in avgt.result(1)] . Now we can scroll through the time-dependent output map using the ipywidgets package: . import ipywidgets as ipw plt.figure() @ipw.interact(i=(0,len(res)-1)) def plot_it(i=0): pm = res[i][0].reshape(rg.shape) Lm = acoular.L_p(pm) plt.imshow(Lm.T, vmin=Lm.max()-15, origin=&#39;lower&#39;, extent=rg.extend()) plt.title(&#39;from sample %i to %i&#39; % (i*6400,i*6400+6399)) . This notebook is an Open Educational Resource. Feel free to use it for your own purposes. The text and the images are licensed under Creative Commons Attribution 4.0, and any code under the MIT license. Please attribute the work as follows: Acoular developers, Getting started with Acoular, 2020. .",
            "url": "https://acoular.github.io/blog/2020/03/09/getstart.html",
            "relUrl": "/2020/03/09/getstart.html",
            "date": " • Mar 9, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://acoular.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://acoular.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Acoular is a framework for acoustic beamforming that is written in the Python programming language. It is aimed at applications in acoustic testing. Multichannel data recorded by a microphone array can be processed and analyzed in order to generate mappings of sound source distributions. The maps (acoustic photographs) can then be used to locate sources of interest and to characterize them using their spectra. . A few highlights of the framework: . covers several beamforming algorithms | different advanced deconvolution algorithms | both time-domain and frequency-domain operation included | 3D mapping possible | application for stationary and for moving targets | supports both scripting and graphical user interface | efficient: intelligent caching, parallel computing with Numba | easily extendible and well documented | .",
          "url": "https://acoular.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://acoular.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}